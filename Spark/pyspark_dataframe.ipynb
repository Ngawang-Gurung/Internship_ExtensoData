{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Note:- Downgrade to Python 3.11.8 or lower to resolve Py4J error* \\\n",
    " *Encounterd lots of Py4J error in Python 3.12.3 such as crashed, cannot find Python3, etc.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+\n",
      "|  a|  b|      c|         d|\n",
      "+---+---+-------+----------+\n",
      "|  1|2.0|string1|2000-01-01|\n",
      "|  2|3.0|string2|2000-02-01|\n",
      "+---+---+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating df from a list of rows\n",
    "\n",
    "from datetime import datetime, date\n",
    "from pyspark.sql import Row\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    Row(a = 1, b = 2., c='string1', d = date(2000, 1, 1)),\n",
    "    Row(a = 2, b = 3., c='string2', d = date(2000, 2, 1)),\n",
    "])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
      "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating df with an explicit schema\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
    "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
    "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
    "], schema='a long, b double, c string, d date, e timestamp')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating spark dataframe from a pandas dataframe\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "\n",
    "pandas_df = pd.DataFrame({\n",
    "    'a': [1, 2, 3],\n",
    "    'b': [2., 3., 4.],\n",
    "    'c': ['string1', 'string2', 'string3'],\n",
    "    'd': [date(2000, 1, 1), date(2000, 2, 1), date(2000, 3, 1)],\n",
    "    'e': [datetime(2000, 1, 1, 12, 0), datetime(2000, 1, 2, 12, 0), datetime(2000, 1, 3, 12, 0)]\n",
    "})\n",
    "df = spark.createDataFrame(pandas_df)\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ngawang Gurung\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\pandas\\__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pyspark.pandas.frame.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating pandas-on-Spark Dataframe\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "\n",
    "pdf = pd.DataFrame(np.random.randn(6, 4), columns=list('ABCD'))\n",
    "psdf = ps.from_pandas(pdf)\n",
    "type(psdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geting Data In/Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('./dataset/OnlineRetail.csv', header = True)\n",
    "\n",
    "# df.write.csv('OnlineRetail.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/2010 8:26|     2.55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|12/1/2010 8:26|     2.75|     17850|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>InvoiceNo</th><th>StockCode</th><th>Description</th><th>Quantity</th><th>InvoiceDate</th><th>UnitPrice</th><th>CustomerID</th><th>Country</th></tr>\n",
       "<tr><td>536365</td><td>85123A</td><td>WHITE HANGING HEA...</td><td>6</td><td>12/1/2010 8:26</td><td>2.55</td><td>17850</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536365</td><td>71053</td><td>WHITE METAL LANTERN</td><td>6</td><td>12/1/2010 8:26</td><td>3.39</td><td>17850</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536365</td><td>84406B</td><td>CREAM CUPID HEART...</td><td>8</td><td>12/1/2010 8:26</td><td>2.75</td><td>17850</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536365</td><td>84029G</td><td>KNITTED UNION FLA...</td><td>6</td><td>12/1/2010 8:26</td><td>3.39</td><td>17850</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536365</td><td>84029E</td><td>RED WOOLLY HOTTIE...</td><td>6</td><td>12/1/2010 8:26</td><td>3.39</td><td>17850</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536365</td><td>22752</td><td>SET 7 BABUSHKA NE...</td><td>2</td><td>12/1/2010 8:26</td><td>7.65</td><td>17850</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536365</td><td>21730</td><td>GLASS STAR FROSTE...</td><td>6</td><td>12/1/2010 8:26</td><td>4.25</td><td>17850</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536366</td><td>22633</td><td>HAND WARMER UNION...</td><td>6</td><td>12/1/2010 8:28</td><td>1.85</td><td>17850</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536366</td><td>22632</td><td>HAND WARMER RED P...</td><td>6</td><td>12/1/2010 8:28</td><td>1.85</td><td>17850</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536367</td><td>84879</td><td>ASSORTED COLOUR B...</td><td>32</td><td>12/1/2010 8:34</td><td>1.69</td><td>13047</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536367</td><td>22745</td><td>POPPY'S PLAYHOUSE...</td><td>6</td><td>12/1/2010 8:34</td><td>2.1</td><td>13047</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536367</td><td>22748</td><td>POPPY'S PLAYHOUSE...</td><td>6</td><td>12/1/2010 8:34</td><td>2.1</td><td>13047</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536367</td><td>22749</td><td>FELTCRAFT PRINCES...</td><td>8</td><td>12/1/2010 8:34</td><td>3.75</td><td>13047</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536367</td><td>22310</td><td>IVORY KNITTED MUG...</td><td>6</td><td>12/1/2010 8:34</td><td>1.65</td><td>13047</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536367</td><td>84969</td><td>BOX OF 6 ASSORTED...</td><td>6</td><td>12/1/2010 8:34</td><td>4.25</td><td>13047</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536367</td><td>22623</td><td>BOX OF VINTAGE JI...</td><td>3</td><td>12/1/2010 8:34</td><td>4.95</td><td>13047</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536367</td><td>22622</td><td>BOX OF VINTAGE AL...</td><td>2</td><td>12/1/2010 8:34</td><td>9.95</td><td>13047</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536367</td><td>21754</td><td>HOME BUILDING BLO...</td><td>3</td><td>12/1/2010 8:34</td><td>5.95</td><td>13047</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536367</td><td>21755</td><td>LOVE BUILDING BLO...</td><td>3</td><td>12/1/2010 8:34</td><td>5.95</td><td>13047</td><td>United Kingdom</td></tr>\n",
       "<tr><td>536367</td><td>21777</td><td>RECIPE BOX WITH M...</td><td>4</td><td>12/1/2010 8:34</td><td>7.95</td><td>13047</td><td>United Kingdom</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
       "|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n",
       "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
       "|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/2010 8:26|     2.55|     17850|United Kingdom|\n",
       "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
       "|   536365|   84406B|CREAM CUPID HEART...|       8|12/1/2010 8:26|     2.75|     17850|United Kingdom|\n",
       "|   536365|   84029G|KNITTED UNION FLA...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
       "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
       "|   536365|    22752|SET 7 BABUSHKA NE...|       2|12/1/2010 8:26|     7.65|     17850|United Kingdom|\n",
       "|   536365|    21730|GLASS STAR FROSTE...|       6|12/1/2010 8:26|     4.25|     17850|United Kingdom|\n",
       "|   536366|    22633|HAND WARMER UNION...|       6|12/1/2010 8:28|     1.85|     17850|United Kingdom|\n",
       "|   536366|    22632|HAND WARMER RED P...|       6|12/1/2010 8:28|     1.85|     17850|United Kingdom|\n",
       "|   536367|    84879|ASSORTED COLOUR B...|      32|12/1/2010 8:34|     1.69|     13047|United Kingdom|\n",
       "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|12/1/2010 8:34|      2.1|     13047|United Kingdom|\n",
       "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|12/1/2010 8:34|      2.1|     13047|United Kingdom|\n",
       "|   536367|    22749|FELTCRAFT PRINCES...|       8|12/1/2010 8:34|     3.75|     13047|United Kingdom|\n",
       "|   536367|    22310|IVORY KNITTED MUG...|       6|12/1/2010 8:34|     1.65|     13047|United Kingdom|\n",
       "|   536367|    84969|BOX OF 6 ASSORTED...|       6|12/1/2010 8:34|     4.25|     13047|United Kingdom|\n",
       "|   536367|    22623|BOX OF VINTAGE JI...|       3|12/1/2010 8:34|     4.95|     13047|United Kingdom|\n",
       "|   536367|    22622|BOX OF VINTAGE AL...|       2|12/1/2010 8:34|     9.95|     13047|United Kingdom|\n",
       "|   536367|    21754|HOME BUILDING BLO...|       3|12/1/2010 8:34|     5.95|     13047|United Kingdom|\n",
       "|   536367|    21755|LOVE BUILDING BLO...|       3|12/1/2010 8:34|     5.95|     13047|United Kingdom|\n",
       "|   536367|    21777|RECIPE BOX WITH M...|       4|12/1/2010 8:34|     7.95|     13047|United Kingdom|\n",
       "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['InvoiceNo',\n",
       " 'StockCode',\n",
       " 'Description',\n",
       " 'Quantity',\n",
       " 'InvoiceDate',\n",
       " 'UnitPrice',\n",
       " 'CustomerID',\n",
       " 'Country']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------------------+------------------+---------------+------------------+------------------+-----------+\n",
      "|summary|         InvoiceNo|         StockCode|         Description|          Quantity|    InvoiceDate|         UnitPrice|        CustomerID|    Country|\n",
      "+-------+------------------+------------------+--------------------+------------------+---------------+------------------+------------------+-----------+\n",
      "|  count|            541909|            541909|              540455|            541909|         541909|            541909|            406829|     541909|\n",
      "|   mean|  559965.752026781|27623.240210938104|             20713.0|  9.55224954743324|           NULL|4.6111136260897085|15287.690570239585|       NULL|\n",
      "| stddev|13428.417280796779|16799.737628427658|                NULL|218.08115785023438|           NULL| 96.75985306117963|1713.6003033215982|       NULL|\n",
      "|    min|            536365|             10002| 4 PURPLE FLOCK D...|                -1|1/10/2011 10:04|         -11062.06|             12346|  Australia|\n",
      "|    max|           C581569|                 m|   wrongly sold sets|               992|  9/9/2011 9:52|             99.96|             18287|Unspecified|\n",
      "+-------+------------------+------------------+--------------------+------------------+---------------+------------------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary of DataFrame\n",
    "\n",
    "df.select(\"*\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER        6   \n",
       "1    536365     71053                  WHITE METAL LANTERN        6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER        8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE        6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.        6   \n",
       "\n",
       "      InvoiceDate UnitPrice CustomerID         Country  \n",
       "0  12/1/2010 8:26      2.55      17850  United Kingdom  \n",
       "1  12/1/2010 8:26      3.39      17850  United Kingdom  \n",
       "2  12/1/2010 8:26      2.75      17850  United Kingdom  \n",
       "3  12/1/2010 8:26      3.39      17850  United Kingdom  \n",
       "4  12/1/2010 8:26      3.39      17850  United Kingdom  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversion to Pandas DataFrame\n",
    "\n",
    "df.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting and Accessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'InvoiceNo'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PySpark DataFrame is lazily evaluated and simply selecting a column does not \n",
    "# trigger the computation but it returns a Column instance.\n",
    "df.InvoiceNo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|InvoiceNo|\n",
      "+---------+\n",
      "|   536365|\n",
      "|   536365|\n",
      "|   536365|\n",
      "|   536365|\n",
      "|   536365|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  DataFrame.select() takes the Column instances that returns another DataFrame.\n",
    "\n",
    "df.select(df.InvoiceNo).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|         Upper|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/2010 8:26|     2.55|     17850|United Kingdom|UNITED KINGDOM|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|UNITED KINGDOM|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|12/1/2010 8:26|     2.75|     17850|United Kingdom|UNITED KINGDOM|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|UNITED KINGDOM|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|UNITED KINGDOM|\n",
      "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To assign new column instance\n",
    "\n",
    "from pyspark.sql.functions import upper\n",
    "df.withColumn('Upper', upper(df.Country)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+---------------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|    InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+--------------------+--------+---------------+---------+----------+-------+\n",
      "|   536527|    22809|SET OF 6 T-LIGHTS...|       6|12/1/2010 13:04|     2.95|     12662|Germany|\n",
      "|   536527|    84347|ROTATING SILVER A...|       6|12/1/2010 13:04|     2.55|     12662|Germany|\n",
      "|   536527|    84945|MULTI COLOUR SILV...|      12|12/1/2010 13:04|     0.85|     12662|Germany|\n",
      "|   536527|    22242|5 HOOK HANGER MAG...|      12|12/1/2010 13:04|     1.65|     12662|Germany|\n",
      "|   536527|    22244|3 HOOK HANGER MAG...|      12|12/1/2010 13:04|     1.95|     12662|Germany|\n",
      "+---------+---------+--------------------+--------+---------------+---------+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To select a subset of rows\n",
    "\n",
    "df.filter(df.Country == 'Germany').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Datatype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import col\n",
    "df = df.withColumn(\"Quantity\", col(\"Quantity\").cast(\"integer\"))\n",
    "df = df.withColumn(\"UnitPrice\", col(\"UnitPrice\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+\n",
      "|CustomerID|     avg(Quantity)|    avg(UnitPrice)|\n",
      "+----------+------------------+------------------+\n",
      "|     16250| 8.666666666666666|             2.375|\n",
      "|     15574|2.0773809523809526|               2.0|\n",
      "|     15555| 4.767567567567568| 1.172972972972973|\n",
      "|     15271| 4.570909090909091|              2.12|\n",
      "|     17714|               9.2|               1.6|\n",
      "|     17757|  4.46900269541779|2.1361185983827493|\n",
      "|     17551| 3.488372093023256|1.9767441860465116|\n",
      "|     13187|2.5675675675675675| 3.189189189189189|\n",
      "|     16549|2.4108053007135575|1.5168195718654434|\n",
      "|     12637| 7.588832487309645|2.0913705583756346|\n",
      "|     15052|2.7333333333333334|2.8666666666666667|\n",
      "|     14525|  8.93288590604027| 2.661073825503356|\n",
      "|     18283| 1.847883597883598|1.0833333333333333|\n",
      "|     13107|21.466666666666665|1.2833333333333334|\n",
      "|     16303|15.694610778443113|2.2335329341317367|\n",
      "|     13174| 4.442675159235669| 2.767515923566879|\n",
      "|     13027| 664.6153846153846|               0.0|\n",
      "|     12957| 10.37295081967213|              2.25|\n",
      "|     17128| 5.428571428571429|3.2142857142857144|\n",
      "|     14439|           16.4375|           5.78125|\n",
      "+----------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Groupby aggregation works on numeric columns only\n",
    "df.groupby('CustomerID').avg().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with SQL\n",
    "\n",
    "DataFrame and Spark SQL share the same execution engine so they can be interchangeably used seamlessly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  541909|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"tableA\")\n",
    "spark.sql(\"SELECT count(*) from tableA\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
