{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from Levenshtein import distance\n",
    "\n",
    "def load_df(filename):\n",
    "    return pd.read_csv(f'./dataset/{filename}.csv')\n",
    "\n",
    "layout1 = load_df('ABC_layout_1')\n",
    "layout2 = load_df('PQR_layout_2')\n",
    "layout3 = load_df('layout_3_voters')\n",
    "layout4 = load_df('KLM_layout_4')\n",
    "layout5 = load_df('layout_5_license')\n",
    "\n",
    "layout1 = layout1.rename(columns={\"First Name\": \"Name\", \"Father Name\": \"Father_Name\", \"Permanent_Adress\":\"Permanent_Address\"})\n",
    "layout2 = layout2.rename(columns = {\"Customer_ID\": \"Mobile Number\"})\n",
    "layout3 = layout3.rename(columns={\"votersName\": \"Name\", \"votersFatherName\": \"Father_Name\", \"votersMotherName\": \"Mother Name\", \" Gender\": \"Gender\", \"Permanent_Adress\":\"Permanent_Address\"})\n",
    "layout4 = layout4.rename(columns={\"Father Name\": \"Father_Name\"})\n",
    "\n",
    "def sanitize(df):\n",
    "    return df.map(lambda x: x.replace(',', '').replace(' ', '').strip() if isinstance(x, str) else '' if pd.isna(x) else x)\n",
    "\n",
    "layouts = [layout1, layout2, layout3, layout4, layout5]\n",
    "layout_copies = [layout.copy() for layout in layouts]\n",
    "\n",
    "for i in range(len(layout_copies)):\n",
    "    layout_copies[i] = sanitize(layout_copies[i])\n",
    "\n",
    "def create_soup(df, df_, soup, soup_name):\n",
    "    df[soup_name] = df_[soup].apply(lambda x: ' '.join(x.values.astype(str)).lower(), axis=1)\n",
    "\n",
    "soup = ['Name', 'Date of Birth', 'Father_Name']\n",
    "\n",
    "for i, j, k, in zip(layouts, layout_copies, range(len(layouts))):\n",
    "    create_soup(i, j, soup, f\"soup{k+1}\")\n",
    "\n",
    "def combine_layouts(A, B, soup_A, soup_B, threshold=0.3):\n",
    "\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    combined_soup = pd.concat([A[soup_A], B[soup_B]], ignore_index=True)\n",
    "    tfidf.fit(combined_soup)\n",
    "    \n",
    "    tfidf_matrix_A = tfidf.transform(A[soup_A])\n",
    "    tfidf_matrix_B = tfidf.transform(B[soup_B])\n",
    "    \n",
    "    similarity = cosine_similarity(tfidf_matrix_A, tfidf_matrix_B)\n",
    "    similarity_df = pd.DataFrame(similarity, index=A.index, columns=B.index)\n",
    "\n",
    "    max_idx_row = similarity_df.idxmax(axis=1)\n",
    "    similarity_mask = similarity_df.max(axis=1) > threshold\n",
    "\n",
    "    # Initialize the combined DataFrame with all columns from both DataFrames\n",
    "    combined_columns = list(set(A.columns) | set(B.columns))\n",
    "    combined_data = pd.DataFrame(columns=combined_columns)\n",
    "    \n",
    "    # Merge the similar rows \n",
    "    for idx_A in A.index:\n",
    "        if similarity_mask[idx_A]:\n",
    "            idx_B = max_idx_row[idx_A]\n",
    "            combined_row = A.loc[idx_A].combine_first(B.loc[idx_B])\n",
    "        else:\n",
    "            combined_row = A.loc[idx_A]\n",
    "        combined_data = pd.concat([combined_data, combined_row.to_frame().T], ignore_index=True)\n",
    "    \n",
    "    # Append non-similar rows from B to A\n",
    "    new_records = B.loc[~B.index.isin(max_idx_row[similarity_mask].values)]\n",
    "    result = pd.concat([combined_data, new_records], ignore_index=True)\n",
    "    result.drop(columns=soup_B, inplace=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "result_12 = combine_layouts(layout1, layout2, 'soup1', 'soup2')\n",
    "result_123 = combine_layouts(result_12, layout3, 'soup1', 'soup3')\n",
    "result_1234 = combine_layouts(result_123, layout4, 'soup1', 'soup4')\n",
    "final_result = combine_layouts(result_1234, layout5, 'soup1', 'soup5')\n",
    "final_result.drop(columns='soup1', inplace=True)\n",
    "final_result"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
