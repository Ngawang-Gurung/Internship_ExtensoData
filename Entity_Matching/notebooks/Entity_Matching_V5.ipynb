{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changelog\n",
    "\n",
    "- Need to create dynamic data loading/preprocessing/saving (for any number of files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from Levenshtein import distance\n",
    "from datetime import datetime \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_from_dir(dir_path):\n",
    "    csv_files = [f for f in os.listdir(dir_path) if f.endswith(\".csv\")]\n",
    "    layouts = []\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(dir_path, csv_file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        # df['source'] = os.path.splitext(csv_file)[0]\n",
    "        layouts.append(df)\n",
    "    \n",
    "    return layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": "layouts = load_df_from_dir('data')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layout in layouts:\n",
    "    layout['last_modified_date'] = datetime.now()\n",
    "\n",
    "def sanitize(df):\n",
    "    return df.map(lambda x: x.replace(',', '').replace(' ', '').strip() if isinstance(x, str) else '' if pd.isna(x) else x)\n",
    "    \n",
    "def create_soup(df, df_, soup, soup_name):\n",
    "    df[soup_name] = df_[soup].apply(lambda x: ' '.join(x.values.astype(str)).lower(), axis=1)\n",
    "\n",
    "layout_copies = [layout.copy() for layout in layouts]\n",
    "soup = ['Name', 'Date of Birth', 'Father_Name']\n",
    "\n",
    "for layout, layout_copy, in zip(layouts, layout_copies):\n",
    "    layout_copy = sanitize(layout_copy)\n",
    "    create_soup(layout, layout_copy, soup, \"soup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_layouts(A, B, metric='cosine', threshold=0.8):\n",
    "    def calculate_similarity(A, B, metric):\n",
    "        if metric == 'cosine':\n",
    "            tfidf = TfidfVectorizer(stop_words='english')\n",
    "            combined_soup = pd.concat([A['soup'], B['soup']], ignore_index=True)\n",
    "            tfidf.fit(combined_soup)\n",
    "            tfidf_matrix_A = tfidf.transform(A['soup'])\n",
    "            tfidf_matrix_B = tfidf.transform(B['soup'])\n",
    "            similarity = cosine_similarity(tfidf_matrix_A, tfidf_matrix_B)\n",
    "            similarity_df = pd.DataFrame(similarity, index=A.index, columns=B.index)\n",
    "            idx_row = similarity_df.idxmax(axis=1)\n",
    "            similarity_mask = similarity_df.max(axis=1) > threshold\n",
    "        else:\n",
    "            distance_matrix = pd.DataFrame([[distance(a, b) for b in B['soup']] for a in A['soup']], index=A.index, columns=B.index)\n",
    "            idx_row = distance_matrix.idxmin(axis=1)\n",
    "            similarity_mask = distance_matrix.min(axis=1) <= threshold\n",
    "        return idx_row, similarity_mask\n",
    "\n",
    "    def merge_data(A, B, idx_row, similarity_mask):\n",
    "        combined_columns = list(set(A.columns) | set(B.columns))\n",
    "        combined_data = pd.DataFrame(columns=combined_columns)\n",
    "        for idx_A in A.index:\n",
    "            if similarity_mask[idx_A]:\n",
    "                idx_B = idx_row[idx_A]\n",
    "                combined_row = A.loc[idx_A].combine_first(B.loc[idx_B])\n",
    "                combined_row['source'] = f\"{A.loc[idx_A]['source']}, {B.loc[idx_B]['source']}\"\n",
    "                combined_row['last_modified_date'] = datetime.now()\n",
    "            else:\n",
    "                combined_row = A.loc[idx_A]\n",
    "            combined_data = pd.concat([combined_data, combined_row.to_frame().T], ignore_index=True)\n",
    "        new_records = B.loc[~B.index.isin(idx_row[similarity_mask].values)]\n",
    "        return pd.concat([combined_data, new_records], ignore_index=True)\n",
    "\n",
    "    idx_row, similarity_mask = calculate_similarity(A, B, metric)\n",
    "    return merge_data(A, B, idx_row, similarity_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save final result only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_digit(char):\n",
    "    if char.isdigit():\n",
    "        return int(char)\n",
    "    elif char.isalpha():\n",
    "        return (ord(char.lower()) - ord('a') + 1) % 10\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def string_to_digits(s):\n",
    "    digits = [char_to_digit(char) for char in s]\n",
    "    numeric_string = ''.join(map(str, digits))\n",
    "    \n",
    "    if len(numeric_string) > 13:\n",
    "        return numeric_string[:13]\n",
    "    else:\n",
    "        return numeric_string.ljust(13, '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_layouts(layouts, save_path):\n",
    "    final_df = layouts[0]\n",
    "\n",
    "    for df in layouts[1:]:\n",
    "        final_df = combine_layouts(final_df, df)\n",
    "    \n",
    "    final_df['uuid'] = final_df['soup'].apply(string_to_digits)\n",
    "    final_df.to_csv('final_result.csv', index=False)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = save_layouts(layouts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save DF in List to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# def save_dfs_to_csv(layouts, output_dir):\n",
    "\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "#     for i, df in enumerate(layouts, start=1):\n",
    "#         file_name = f\"layout{i}.csv\"\n",
    "#         file_path = os.path.join(output_dir, file_name)\n",
    "#         df.to_csv(file_path, index=False)\n",
    "#         print(f\"Saved {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Ways to Save Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Intermittent Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_layouts(layouts, save_path):\n",
    "#     final_df = layouts[0]\n",
    "#     results = [final_df] \n",
    "\n",
    "#     initial_part = \"1\"   \n",
    "#     for i, df in enumerate(layouts[1:], start=2):\n",
    "#         final_df = combine_layouts(final_df, df)\n",
    "#         results.append(final_df)\n",
    "        \n",
    "#         initial_part += str(i)\n",
    "#         final_df.to_csv(f\"./{save_path}/result{initial_part}.csv\", index=False)\n",
    "    \n",
    "#     return final_df, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df, results = save_layouts(layouts, 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save final_result and delete source files if successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "\n",
    "# def save_layouts(layouts, save_path, save_filename):\n",
    "#     final_df = layouts[0]\n",
    "\n",
    "#     for df in layouts[1:]:\n",
    "#         final_df = combine_layouts(final_df, df)\n",
    "    \n",
    "#     final_result_path = os.path.join(save_path, save_filename)\n",
    "    \n",
    "#     try:\n",
    "#         final_df.to_csv(final_result_path, index=False)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error saving final result: {e}\")\n",
    "#         return None\n",
    "\n",
    "#     # If save is successful, delete all other files in save_path except final_result\n",
    "#     files = glob.glob(os.path.join(save_path, '*'))\n",
    "#     for f in files:\n",
    "#         if f != final_result_path:\n",
    "#             os.remove(f)\n",
    "\n",
    "#     return final_df\n",
    "\n",
    "# final_df = save_layouts(layouts, 'results', 'final_result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
