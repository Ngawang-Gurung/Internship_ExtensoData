{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from Levenshtein import distance"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "def load_df(filename):\n",
    "    return pd.read_csv(f'./dataset/{filename}.csv')\n",
    "\n",
    "layout1 = load_df('ABC_layout_1')\n",
    "layout2 = load_df('PQR_layout_2')\n",
    "layout3 = load_df('layout_3_voters')\n",
    "layout4 = load_df('KLM_layout_4')\n",
    "layout5 = load_df('layout_5_license')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "layout1 = layout1.rename(columns={\"First Name\": \"Name\", \"Father Name\": \"Father_Name\", \"Permanent_Adress\":\"Permanent_Address\"})\n",
    "layout2 = layout2.rename(columns = {\"Customer_ID\": \"Mobile Number\"})\n",
    "layout3 = layout3.rename(columns={\"votersName\": \"Name\", \"votersFatherName\": \"Father_Name\", \"votersMotherName\": \"Mother Name\", \" Gender\": \"Gender\", \"Permanent_Adress\":\"Permanent_Address\"})\n",
    "layout4 = layout4.rename(columns={\"Father Name\": \"Father_Name\"})"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "def sanitize(df):\n",
    "    return df.map(lambda x: x.replace(',', '').replace(' ', '').strip() if isinstance(x, str) else x)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "layouts = [layout1, layout2, layout3, layout4, layout5]\n",
    "layout_copies = [layout.copy() for layout in layouts]\n",
    "\n",
    "for i in range(len(layout_copies)):\n",
    "    layout_copies[i] = sanitize(layout_copies[i])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Composite-keys *for* Entity Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "def create_soup(df, df_, soup, soup_name):\n",
    "    df[soup_name] = df_[soup].apply(lambda x: ' '.join(x.values.astype(str)).lower(), axis=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "soup = ['Name', 'Date of Birth', 'Father_Name']\n",
    "\n",
    "for i, j, k, in zip(layouts, layout_copies, range(len(layouts))):\n",
    "    create_soup(i, j, soup, f\"soup{k+1}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicate Columns After Merging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "def column_remover(df):\n",
    "\n",
    "    columns = [\"Name\", \"Date of Birth\", \"Father_Name\", \"Temporary_Address\", \"Mobile Number\", \"Permanent_Address\",  \"Mother Name\", \"Gender\"]\n",
    "    column_pairs = [(col, f\"{col}_x\", f\"{col}_y\") for col in columns]\n",
    "\n",
    "    for new_col, col_x, col_y in column_pairs:\n",
    "        if col_x in df.columns and col_y in df.columns:\n",
    "            df[new_col] = df[col_x].combine_first(df[col_y])\n",
    "            df.drop([col_x, col_y], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Matching Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# def combine_layouts(A, B, soup_A, soup_B, threshold=0):\n",
    "#     tfidf = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "#     combined_soup = pd.concat([A[soup_A], B[soup_B]], ignore_index=True)\n",
    "#     tfidf.fit(combined_soup)\n",
    "    \n",
    "#     tfidf_matrix_A = tfidf.transform(A[soup_A])\n",
    "#     tfidf_matrix_B = tfidf.transform(B[soup_B])\n",
    "    \n",
    "#     similarity = cosine_similarity(tfidf_matrix_A, tfidf_matrix_B)\n",
    "#     similarity_df = pd.DataFrame(similarity, index=A.index, columns=B.index)\n",
    "\n",
    "#     max_idx_row = similarity_df.idxmax(axis=1)\n",
    "#     similarity_mask = similarity_df.max(axis=1) > threshold\n",
    "    \n",
    "#     combined_df = pd.DataFrame({\n",
    "#         soup_A: A[soup_A].values,\n",
    "#         soup_B: [B.loc[idx, soup_B] if mask else None for idx, mask in zip(max_idx_row.values, similarity_mask)]\n",
    "#     })\n",
    "\n",
    "#     result = pd.merge(pd.merge(A, combined_df, on=soup_A, how='left'), B, on=soup_B, how='left')\n",
    "#     result.drop(columns=soup_B, inplace=True)\n",
    "#     column_remover(result)\n",
    "#     return result"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "def combine_layouts(A, B, soup_A, soup_B, metric = 'cosine', threshold=0):\n",
    "    if metric == 'cosine':\n",
    "        tfidf = TfidfVectorizer(stop_words='english')\n",
    "        \n",
    "        combined_soup = pd.concat([A[soup_A], B[soup_B]], ignore_index=True)\n",
    "        tfidf.fit(combined_soup)\n",
    "        \n",
    "        tfidf_matrix_A = tfidf.transform(A[soup_A])\n",
    "        tfidf_matrix_B = tfidf.transform(B[soup_B])\n",
    "        \n",
    "        similarity = cosine_similarity(tfidf_matrix_A, tfidf_matrix_B)\n",
    "        similarity_df = pd.DataFrame(similarity, index=A.index, columns=B.index)\n",
    "\n",
    "        max_idx_row = similarity_df.idxmax(axis=1)\n",
    "        similarity_mask = similarity_df.max(axis=1) > threshold\n",
    "        \n",
    "        combined_df = pd.DataFrame({\n",
    "            soup_A: A[soup_A].values,\n",
    "            soup_B: [B.loc[idx, soup_B] if mask else None for idx, mask in zip(max_idx_row.values, similarity_mask)]\n",
    "        })\n",
    "    elif metric == 'levenshtein':\n",
    "        distance_matrix = pd.DataFrame(np.zeros((len(A), len(B))), index=A.index, columns=B.index)\n",
    "\n",
    "        for i in A.index:\n",
    "            for j in B.index:\n",
    "                distance_matrix.loc[i, j] = distance(A.loc[i, soup_A], B.loc[j, soup_B])\n",
    "\n",
    "        min_idx_row = distance_matrix.idxmin(axis=1)\n",
    "        min_distance = distance_matrix.min(axis=1)\n",
    "\n",
    "        distance_mask = min_distance <= threshold\n",
    "\n",
    "        combined_df = pd.DataFrame({\n",
    "            soup_A: A[soup_A].values,\n",
    "            soup_B: [B.loc[idx, soup_B] if mask else None for idx, mask in zip(min_idx_row.values, distance_mask)]\n",
    "        })\n",
    "\n",
    "    result = pd.merge(pd.merge(A, combined_df, on=soup_A, how='left'), B, on=soup_B, how='left')\n",
    "    result.drop(columns=soup_B, inplace=True)\n",
    "    column_remover(result)\n",
    "    return result"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Super Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "result_12 = combine_layouts(layout1, layout2, 'soup1', 'soup2')\n",
    "result_123 = combine_layouts(result_12, layout3, 'soup1', 'soup3')\n",
    "result_1234 = combine_layouts(result_123, layout4, 'soup1', 'soup4')\n",
    "final_result = combine_layouts(result_1234, layout5, 'soup1', 'soup5')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "del final_result['soup1']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "final_result.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "final_result.shape"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
